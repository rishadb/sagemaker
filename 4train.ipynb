{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d688d9-1526-4384-8d5f-ce0215ad6422",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train a review classifier with BERT and Amazon SageMaker\n",
    "##### train a text classifier using a variant of BERT called RoBERTa - a Robustly Optimized BERT Pretraining Approach - within a PyTorch model ran as a SageMaker Training Job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b93b06-cdf6-4eed-a084-ac1dac54f59a",
   "metadata": {},
   "source": [
    "Let's review Amazon SageMaker \"Bring Your Own Script\" scheme.:\n",
    "\n",
    "![](sagemaker_scriptmode.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab8c54-562a-4c28-997e-beceb007abfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please ignore warning messages during the installation\n",
    "!pip install --disable-pip-version-check -q sagemaker==2.35.0\n",
    "!conda install -q -y pytorch==1.6.0 -c pytorch\n",
    "!pip install --disable-pip-version-check -q transformers==3.5.1\n",
    "\n",
    "import boto3, sagemaker, pandas as pd, numpy as np, botocore\n",
    "\n",
    "config = botocore.config.Config(user_agent_extra='dlai-pds/c2/w2')\n",
    "\n",
    "# low-level service client of the boto3 session\n",
    "sm = boto3.client(service_name='sagemaker', config=config)\n",
    "sm_runtime = boto3.client('sagemaker-runtime', config=config)\n",
    "sess = sagemaker.Session(sagemaker_client=sm, sagemaker_runtime_client=sm_runtime)\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sess.boto_region_name\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d466d56-a55f-403a-a2bc-685ef22a7d64",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configure dataset, hyper-parameters and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f7a84-ff01-4243-b4c1-b23d50af20e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a train and validation data channel\n",
    "processed_train_data_s3_uri= \"s3://sagemaker-us-east-1-170235698766/sagemaker-scikit-learn-2022-07-26-06-44-43-422/output/sentiment-train/\"\n",
    "processed_validation_data_s3_uri= \"s3://sagemaker-us-east-1-170235698766/sagemaker-scikit-learn-2022-07-26-06-44-43-422/output/sentiment-validation/\"\n",
    "\n",
    "s3_input_train_data = sagemaker.inputs.TrainingInput(s3_data= processed_train_data_s3_uri) # sagemaker sdk automatically write this data to s3 for you\n",
    "s3_input_validation_data = sagemaker.inputs.TrainingInput(s3_data= processed_validation_data_s3_uri)\n",
    "\n",
    "data_channels = { 'train': processed_train_data_s3_uri, 'validation': s3_input_validation_data }\n",
    "\n",
    "#emli-channel: train_data = sagemaker.session.s3_input(s3_train_data, distribution=\"FullyReplicated\", content_type=\"text/plain\", s3_data_type= S3Prefix)\n",
    "\n",
    "#Configure model hyper-parameters\n",
    "max_seq_length=128 # maximum number of input tokens passed to BERT model\n",
    "freeze_bert_layer=False # specifies the depth of training within the network\n",
    "epochs=3; learning_rate=2e-5; train_batch_size=256; train_steps_per_epoch=50; validation_batch_size=256; validation_steps_per_epoch=50\n",
    "seed=42; run_validation=True; train_instance_count=1; train_instance_type='ml.p2.xlarge'; train_volume_size=256; input_mode='File'\n",
    "\n",
    "#PyTorch estimator hyperparameters argument.\n",
    "hyperparameters={'max_seq_length': max_seq_length,'freeze_bert_layer': freeze_bert_layer,'epochs': epochs,'learning_rate': learning_rate,'train_batch_size': train_batch_size,'train_steps_per_epoch': train_steps_per_epoch,'validation_batch_size': validation_batch_size,'validation_steps_per_epoch': validation_steps_per_epoch,    'seed': seed,'run_validation': run_validation}\n",
    "\n",
    "#Setup evaluation metrics; \n",
    "#Choose loss and accuracy as the evaluation metrics.`Regex` will capture the values of metrics that the algorithm will emit and produce the metrics graph in CloudWatch:\n",
    "metric_definitions = [{'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9.]+)'}, {'Name': 'validation:accuracy', 'Regex': 'val_acc: ([0-9.]+)'},]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2ac5d4-a306-4d35-bb68-deeda4e51fc7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Setup Debugger and Profiler\n",
    "Amazon SageMaker Debugger can be used to profile machine learning models, helping to identify and fix training issues caused by hardware resource usage. Setting some parameters in the SageMaker estimator, without any change to the training code, you can enable the collection of infrastructure and model metrics such as: CPU and GPU, RAM and GPU RAM, data loading time, time spent in ML operators running on CPU and GPU, distributed training metrics and many more. In addition, you can visualize how much time is spent in different phases, such as preprocessing, training loop, and postprocessing. If needed, you can drill down on each training epoch, and even on each function in your training script.\n",
    "\n",
    "Define Debugger Rules as described here: https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebfefb1-0020-4df8-8a0a-7f617099ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "from sagemaker.debugger import DebuggerHookConfig #provides options to customize how debugging information is emitted and saved.\n",
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile #ProfilerConfig sets the configuration for collecting system and framework metrics of SageMaker Training Jobs.\n",
    "\n",
    "debugger_hook_config = DebuggerHookConfig(s3_output_path='s3://{}'.format(bucket),) #debugger output stored in this s3 location\n",
    "\n",
    "profiler_config = ProfilerConfig(system_monitor_interval_millis=500,#sets the time interval to collect system metrics (in milliseconds)\n",
    "    framework_profile_params=FrameworkProfile(local_path=\"/opt/ml/output/profiler/\",  # the object for framework metrics profiling.\n",
    "                                              start_step=5, #step at which to start profiling\n",
    "                                              num_steps=10)) #the number of steps to profile\n",
    "\n",
    "#For monitoring and profiling the built-in rules you can use the ProfilerReport. It creates a profiling report and updates when the individual rules are triggered. If you trigger this ProfilerReport rule without any customized parameter as in the cell below, then the ProfilerReport rule triggers all of the built-in rules for monitoring and profiling with their default parameter values. The profiling report can be downloaded while the Training Job is running or after the job has finished.\n",
    "rules=[ProfilerRule.sagemaker(rule_configs.ProfilerReport())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67457629-0ce2-42f2-9731-12115ee4c81f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train model\n",
    "##### Setup the RoBERTa and PyTorch script to run on SageMaker\n",
    "\n",
    "Setup the PyTorch estimator to train our model. For more information on the PyTorch estimator, see the documentation [here](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5330fb-ccf5-4f61-a0f8-c10d966a651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#container = get_image_uri(region, 'xgboost', repo_version = 'latest')\n",
    "#bt_model = sagemaker.estimator.Estimator(container, role, train_instance_count, train_instalnce_type, rtain_volume_size, train_max_run, input_mode, output_path, sagemaker_session)\n",
    "\n",
    "from sagemaker.pytorch import PyTorch as PyTorchEstimator\n",
    "\n",
    "#define estimator\n",
    "estimator = PyTorchEstimator(\n",
    "    entry_point='train.py', source_dir='./c2w2/src', role=role, instance_count=train_instance_count, instance_type=train_instance_type, # pass train instance_type as \"local\" to train locally\n",
    "    volume_size=train_volume_size, py_version='py3', # dynamically retrieves the correct training image (Python 3)\n",
    "    framework_version='1.6.0', # dynamically retrieves the correct training image (PyTorch)\n",
    "    hyperparameters=hyperparameters, metric_definitions=metric_definitions, input_mode=input_mode, debugger_hook_config=debugger_hook_config,\n",
    "    profiler_config=profiler_config, rules=rules  )\n",
    "\n",
    "#Launch estimator/ start training\n",
    "estimator.fit(inputs= data_channels, #, # train and validation input\n",
    "            wait=False ) # do not wait for the job to complete before continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee720d-4103-4a12-937a-86954b603743",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(estimator.latest_training_job.describe().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e3cf54-e8d8-4fd6-a034-45828f1935f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull the Training Job status from the Training Job description.\n",
    "training_job_name = estimator.latest_training_job.describe()['TrainingJobName']\n",
    "training_job_status_primary = estimator.latest_training_job.describe()['TrainingJobStatus'] \n",
    "print('Training Job status: {}'.format(training_job_status_primary))\n",
    "\n",
    "#Review the Training Job in the console.\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/jobs/{}\">Training Job</a></b>'.format(region, training_job_name)))\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&tab=overview\">S3 output data</a> after the Training Job has completed</b>'.format(bucket, training_job_name, region)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33395f6-5a27-4387-a680-8bfbc41e70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wait until the ^^ Training Job ^^ completes above\n",
    "#%%time\n",
    "estimator.latest_training_job.wait(logs=False)\n",
    "df_metrics = estimator.training_job_analytics.dataframe()\n",
    "#You can query and plot the training metrics:\n",
    "df_metrics.query(\"metric_name=='validation:accuracy'\").plot(x='timestamp', y='value')\n",
    "\n",
    "#Analyze Debugger results\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}?prefix={}/\">S3 debugger output data</a></b>'.format(bucket, training_job_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed819d-1c0d-4698-ac2e-11ebf180f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download SageMaker debugger profiling report\n",
    "profiler_report_s3_uri = \"s3://{}/{}/rule-output/ProfilerReport/profiler-output\".format(bucket, training_job_name)\n",
    "!aws s3 ls $profiler_report_s3_uri/\n",
    "!aws s3 cp --recursive $profiler_report_s3_uri ./profiler_report/\n",
    "\n",
    "#review the profiler report in the console\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"./profiler_report/profiler-report.html\">profiler report</a></b>'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46439665-f605-40e3-aae6-f048bd68efe3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1c75da-69ae-43da-a3bf-1f86ead02b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn off the endpoints when not in use with lambda function\n",
    "#use inference pipeline for pre and post processing: can create uptp 5 containers and run the sequentially in same EC2 instance. eg: one contaier-feature processing, passing output to model inferencing cotainer which then passed to post processing which can be like if statement based on the confidence level or something..\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONLinesSerializer\n",
    "from sagemaker.deserializers import JSONLinesDeserializer\n",
    "\n",
    "#Create a custom SentimentPredictor that encapsulates a JSONLines serializer and deserializer. To be passed into the PyTorchModel it needs to be wrapped as a class.\n",
    "class SentimentPredictor(Predictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super().__init__(endpoint_name, sagemaker_session=sagemaker_session, serializer=JSONLinesSerializer(), deserializer=JSONLinesDeserializer())\n",
    "\n",
    "#config a model for deployment\n",
    "import time\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "timestamp = int(time.time())\n",
    "pytorch_model_name = '{}-{}-{}'.format(training_job_name, 'pt', timestamp)\n",
    "\n",
    "model = PyTorchModel(name=pytorch_model_name, model_data=estimator.model_data, predictor_cls=SentimentPredictor, entry_point='inference.py',\n",
    "                     source_dir='src', framework_version='1.6.0', py_version='py3', role=role)\n",
    "\n",
    "#deploy model to an endpoint\n",
    "pytorch_endpoint_name = '{}-{}-{}'.format(training_job_name, 'pt', timestamp)\n",
    "#%%time\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m5.large', endpoint_name=pytorch_endpoint_name) #pass instANCE_TYPE AS \"local\" for local deployment\n",
    "\n",
    "#Review the Endpoint in the AWS console\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST Endpoint</a></b>'.format(region, pytorch_endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a42a112-dc15-45f1-8d40-4444ae7fa781",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test model\n",
    "Here, we will pass sample strings of text to the endpoint in order to see the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f54ef-3f4b-4715-9f0c-f11f6563d448",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    {\"features\": [\"I love this product!\"]},\n",
    "    {\"features\": [\"OK, but not great.\"]},\n",
    "    {\"features\": [\"This is not the right product.\"]},]\n",
    "\n",
    "predictor = SentimentPredictor(endpoint_name=pytorch_endpoint_name, sagemaker_session=sess)\n",
    "predicted_classes = predictor.predict(inputs)\n",
    "\n",
    "for predicted_class in predicted_classes:\n",
    "    print(\"Predicted class {} with probability {}\".format(predicted_class['predicted_label'], predicted_class['probability']))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
