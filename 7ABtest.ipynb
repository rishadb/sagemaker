{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "493840a3-158e-4b76-ae0a-c54a9832c9f3",
   "metadata": {},
   "source": [
    "# A/B testing, traffic shifting and autoscaling\n",
    "create an endpoint with multiple variants, splitting the traffic between them. Then after testing and reviewing the endpoint performance metrics, you will shift the traffic to one variant and configure it to autoscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de00515e-f749-4247-9531-ebddbbb6c130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# please ignore warning messages during the installation\n",
    "!pip install --disable-pip-version-check -q sagemaker==2.35.0\n",
    "!conda install -q -y pytorch==1.6.0 -c pytorch\n",
    "!pip install --disable-pip-version-check -q transformers==3.5.1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import boto3, sagemaker, pandas as pd, botocore\n",
    "\n",
    "config = botocore.config.Config(user_agent_extra='dlai-pds/c3/w2')\n",
    "\n",
    "# low-level service client of the boto3 session\n",
    "sm = boto3.client(service_name='sagemaker', config=config)\n",
    "sm_runtime = boto3.client('sagemaker-runtime', config=config)\n",
    "sess = sagemaker.Session(sagemaker_client=sm, sagemaker_runtime_client=sm_runtime)\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sess.boto_region_name\n",
    "\n",
    "cw = boto3.client(service_name='cloudwatch', config=config)\n",
    "\n",
    "autoscale = boto3.client(service_name=\"application-autoscaling\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58627e-5e0b-43f5-9e8d-86dfe814448c",
   "metadata": {},
   "source": [
    "<a name='c3w2-1.'></a>\n",
    "# 1. Create an endpoint with multiple variants\n",
    "Let's deploy an endpoint splitting the traffic between these two models 50/50 to perform A/B Testing. Instead of creating a PyTorch Model object and calling `model.deploy()` function, you will create an `Endpoint configuration` with multiple model variants. Here is the workflow you will follow to create an endpoint:\n",
    "<img src=\"./c3w2/images/endpoint-workflow.png\" width=\"60%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d287215-4561-4988-b61b-40d0de0e357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two modelsare saved in the following S3 bucket paths.  These `tar.gz` files contain the model artifacts, which result from model training.\n",
    "model_a_s3_uri = 's3://dlai-practical-data-science/models/ab/variant_a/model.tar.gz'\n",
    "model_b_s3_uri = 's3://dlai-practical-data-science/models/ab/variant_b/model.tar.gz'\n",
    "\n",
    "inference_instance_type = 'ml.m5.large'\n",
    "\n",
    "#Create an ECR URI using the 'PyTorch' framework\n",
    "inference_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"pytorch\",version='1.6.0',instance_type=inference_instance_type, \n",
    "    region=region, py_version='py3', image_scope='inference')\n",
    "print(inference_image_uri)\n",
    "\n",
    "#Create Amazon SageMaker Models:\n",
    "import time\n",
    "from pprint import pprint\n",
    "timestamp = int(time.time())\n",
    "model_name_a = '{}-{}'.format('a', timestamp)\n",
    "model_name_b = '{}-{}'.format('b', timestamp)\n",
    "\n",
    "def check_model_existence(model_name): #to check if the model already exists in Amazon SageMaker\n",
    "    for model in sm.list_models()['Models']:\n",
    "        if model_name == model['ModelName']:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "#Create an Amazon SageMaker Model based on the model_a_s3_uri data:\n",
    "if not check_model_existence(model_name_a):\n",
    "    model_a = sm.create_model(ModelName=model_name_a, ExecutionRoleArn=role,\n",
    "                              PrimaryContainer={'ModelDataUrl': model_a_s3_uri, 'Image':inference_image_uri })\n",
    "    pprint(model_a)\n",
    "else:\n",
    "    print(\"Model {} already exists\".format(model_name_a))\n",
    "    \n",
    "#Create an Amazon SageMaker Model based on the model_b_s3_uri data:\n",
    "if not check_model_existence(model_name_b):\n",
    "    model_b = sm.create_model(ModelName=model_name_b, ExecutionRoleArn=role, \n",
    "                              PrimaryContainer={'ModelDataUrl': model_b_s3_uri, 'Image': inference_image_uri})\n",
    "    pprint(model_b)\n",
    "else:\n",
    "    print(\"Model {} already exists\".format(model_name_b))\n",
    "\n",
    "#Set up Amazon SageMaker production variants: A production variant is a packaged SageMaker Model combined with the configuration related to how that model will be hosted.You have constructed the model in the section above. The hosting resources configuration includes information on how you want that model to be hosted: the number and type of instances, a pointer to the SageMaker package model, as well as a variant name and variant weight. A single SageMaker Endpoint can actually include multiple production variants.\n",
    "#Create an Amazon SageMaker production variant for the SageMaker Models\n",
    "from sagemaker.session import production_variant\n",
    "\n",
    "variantA = production_variant(\n",
    "    model_name=model_name_a, instance_type=inference_instance_type,\n",
    "    initial_weight=50,  # traffic distribution weight\n",
    "    initial_instance_count=1, variant_name='VariantA',) # production variant name\n",
    "print(variantA)\n",
    "\n",
    "variantB = production_variant(\n",
    "    model_name=model_name_b, instance_type=inference_instance_type, initial_weight=50, \n",
    "    initial_instance_count=1, variant_name='VariantB',)\n",
    "print(variantB)\n",
    "\n",
    "#Configure and create the endpoint;\n",
    "#Check if the endpoint configuration and endpoint itself already exist in Amazon SageMaker.\n",
    "def check_endpoint_config_existence(endpoint_config_name):\n",
    "    for endpoint_config in sm.list_endpoint_configs()['EndpointConfigs']:\n",
    "        if endpoint_config_name == endpoint_config['EndpointConfigName']:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_endpoint_existence(endpoint_name):\n",
    "    for endpoint in sm.list_endpoints()['Endpoints']:\n",
    "        if endpoint_name == endpoint['EndpointName']:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "#Create the endpoint configuration:\n",
    "endpoint_config_name = '{}-{}'.format('ab', timestamp)\n",
    "\n",
    "if not check_endpoint_config_existence(endpoint_config_name):\n",
    "    endpoint_config = sm.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name, \n",
    "        ProductionVariants=[variantA, variantB])\n",
    "    pprint(endpoint_config)\n",
    "else:\n",
    "    print(\"Endpoint configuration {} already exists\".format(endpoint_config_name))\n",
    "    \n",
    "#Create an endpoint:\n",
    "model_ab_endpoint_name = '{}-{}'.format('ab', timestamp)\n",
    "if not check_endpoint_existence(model_ab_endpoint_name):\n",
    "    endpoint_response = sm.create_endpoint(EndpointName=model_ab_endpoint_name, EndpointConfigName=endpoint_config_name )\n",
    "    print('Creating endpoint {}'.format(model_ab_endpoint_name))\n",
    "    pprint(endpoint_response)\n",
    "else:\n",
    "    print(\"Endpoint {} already exists\".format(model_ab_endpoint_name))\n",
    "\n",
    "#Review the created endpoint configuration and endpoint in the AWS console.\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpointConfig/{}\">REST Endpoint configuration</a></b>'.format(region, endpoint_config_name)))\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST endpoint</a></b>'.format(region, model_ab_endpoint_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc8be09-d895-4d99-ab72-c94f0dc46c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wait for endpoint\n",
    "#%%time\n",
    "waiter = sm.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=model_ab_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfcae8d-50ff-4490-8f00-58e46c84a85d",
   "metadata": {},
   "source": [
    "## Test model on a few sample strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef171e6-7492-43a4-b135-fcd6248d0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an Amazon SageMaker Predictor based on the deployed endpoint:\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONLinesSerializer\n",
    "from sagemaker.deserializers import JSONLinesDeserializer\n",
    "\n",
    "inputs = [{\"features\": [\"I love this product!\"]}, {\"features\": [\"OK, but not great.\"]}, {\"features\": [\"This is not the right product.\"]},]\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=model_ab_endpoint_name,\n",
    "    serializer=JSONLinesSerializer(), #a serializer object, used to encode data for an inference endpoint\n",
    "    deserializer=JSONLinesDeserializer(),sagemaker_session=sess)\n",
    "\n",
    "predicted_classes = predictor.predict(inputs)\n",
    "\n",
    "for predicted_class in predicted_classes:\n",
    "    print(\"Predicted class {} with probability {}\".format(predicted_class['predicted_label'], predicted_class['probability']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cfe94-0dde-40d0-b1d3-424f55b319c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate traffic and review the endpoint performance metrics; Now you will generate traffic. To analyze the endpoint performance you will review some of the metrics that Amazon SageMaker emits in CloudWatch: CPU Utilization, Latency and Invocations. Full list of namespaces and metrics can be found [here](https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-cloudwatch.html). CloudWatch `get_metric_statistics` documentation can be found [here](https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_GetMetricStatistics.html).\n",
    "\n",
    "def plot_endpoint_metrics_for_variants(endpoint_name, namespace_name, metric_name, variant_names, start_time, \n",
    "                                     end_time):\n",
    "    \n",
    "    try:\n",
    "        joint_variant_metrics = None\n",
    "\n",
    "        for variant_name in variant_names:\n",
    "            metrics = cw.get_metric_statistics( # extracts the results in a dictionary format\n",
    "                Namespace=namespace_name, # the namespace of the metric, e.g. \"AWS/SageMaker\"\n",
    "                MetricName=metric_name, # the name of the metric, e.g. \"CPUUtilization\"\n",
    "                StartTime=start_time, # the time stamp that determines the first data point to return\n",
    "                EndTime=end_time, # the time stamp that determines the last data point to return\n",
    "                Period=60, # the granularity, in seconds, of the returned data points\n",
    "                Statistics=[\"Sum\"], # the metric statistics\n",
    "                Dimensions=[ # dimensions, as CloudWatch treats each unique combination of dimensions as a separate metric\n",
    "                    {\"Name\": \"EndpointName\", \"Value\": endpoint_name}, \n",
    "                    {\"Name\": \"VariantName\", \"Value\": variant_name}])\n",
    "            \n",
    "            if metrics[\"Datapoints\"]: # access the results from the distionary using the key \"Datapoints\"\n",
    "                df_metrics = pd.DataFrame(metrics[\"Datapoints\"]) \\\n",
    "                    .sort_values(\"Timestamp\") \\\n",
    "                    .set_index(\"Timestamp\") \\\n",
    "                    .drop(\"Unit\", axis=1) \\\n",
    "                    .rename(columns={\"Sum\": variant_name}) # rename the column with the metric results as a variant_name\n",
    "                \n",
    "                if joint_variant_metrics is None:\n",
    "                    joint_variant_metrics = df_metrics\n",
    "                else:\n",
    "                    joint_variant_metrics = joint_variant_metrics.join(df_metrics, how=\"outer\")\n",
    "        \n",
    "        joint_variant_metrics.plot(title=metric_name)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#Establish wide enough time bounds to show all the charts using the same timeframe:\n",
    "from datetime import datetime, timedelta\n",
    "start_time = datetime.now() - timedelta(minutes=30)\n",
    "end_time = datetime.now() + timedelta(minutes=30)\n",
    "print('Start Time: {}'.format(start_time))\n",
    "print('End Time: {}'.format(end_time))\n",
    "\n",
    "#Set the list of the the variant names to analyze.\n",
    "variant_names = [variantA[\"VariantName\"], variantB[\"VariantName\"]]\n",
    "print(variant_names)\n",
    "\n",
    "#Run some predictions and view the metrics for each variant.\n",
    "#%%time\n",
    "for i in range(0, 100):\n",
    "    predicted_classes = predictor.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5050e511-4792-4fd7-bf32-5dddf58a6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query CloudWatch to get a few metrics that are split across variants. If you see Metrics not yet available, please be patient as metrics may take a few mins to appear in CloudWatch.\n",
    "time.sleep(30) # Sleep to accomodate a slight delay in metrics gathering\n",
    "# CPUUtilization\n",
    "# The sum of each individual CPU core's utilization. \n",
    "# The CPU utilization of each core can range between 0 and 100. For example, if there are four CPUs, CPUUtilization can range from 0% to 400%.\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, namespace_name=\"/aws/sagemaker/Endpoints\", \n",
    "    metric_name=\"CPUUtilization\", variant_names=variant_names, start_time=start_time, end_time=end_time)\n",
    "\n",
    "# Invocations\n",
    "# The number of requests sent to a model endpoint.\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, namespace_name=\"AWS/SageMaker\", metric_name=\"Invocations\",\n",
    "    variant_names=variant_names, start_time=start_time, end_time=end_time)\n",
    "\n",
    "# InvocationsPerInstance\n",
    "# The number of invocations sent to a model, normalized by InstanceCount in each production variant.\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, namespace_name=\"AWS/SageMaker\", metric_name=\"InvocationsPerInstance\",\n",
    "    variant_names=variant_names, start_time=start_time, end_time=end_time)\n",
    "\n",
    "# ModelLatency\n",
    "# The interval of time taken by a model to respond as viewed from SageMaker (in microseconds).\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, namespace_name=\"AWS/SageMaker\", metric_name=\"ModelLatency\",\n",
    "    variant_names=variant_names, start_time=start_time, end_time=end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abad473-71ef-42bc-aa9e-9218e0ce2ffa",
   "metadata": {},
   "source": [
    "## 3. Shift the traffic to one variant and review the endpoint performance metrics\n",
    "Generally, the winning model would need to be chosen. The decision would be made based on the endpoint performance metrics and some other business related evaluations. Here you can assume that the winning model is in the Variant B and shift all traffic to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f255a-b40a-412c-9cbb-695ed419b83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct a list with the updated endpoint weights. No downtime occurs during this traffic-shift activity. this take time\n",
    "\n",
    "updated_endpoint_config = [\n",
    "    {\"VariantName\": variantA[\"VariantName\"],\"DesiredWeight\": 0,},\n",
    "    {\"VariantName\": variantB[\"VariantName\"], \"DesiredWeight\": 100,},]\n",
    "\n",
    "#Update variant weights in the configuration of the existing endpoint. this takes time. There is no downtime while the update is applying.\n",
    "sm.update_endpoint_weights_and_capacities(EndpointName=model_ab_endpoint_name, DesiredWeightsAndCapacities=updated_endpoint_config)\n",
    "\n",
    "#review the endpoint in the AWS console.\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST endpoint</a></b>'.format(region, model_ab_endpoint_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21640e0d-b22f-4013-a60a-c25d3070cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wait\n",
    "waiter = sm.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=model_ab_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b4a8a-cf6e-4c0a-92fa-f420b7b40afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "for i in range(0, 100):\n",
    "    predicted_classes = predictor.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c67b61-d6eb-4fc8-bc83-d1f11a4b2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run some more predictions and view the metrics for each variant.\n",
    "#%%time\n",
    "for i in range(0, 100):\n",
    "    predicted_classes = predictor.predict(inputs)\n",
    "#Μake sure the predictions ^^ above ^^ ran successfully. If you see Metrics not yet available, please be patient as metrics may take a few minutes to appear in CloudWatch. Compare the results with the plots above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef5b1b5-92d8-4721-9134-c14e3db54351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPUUtilization\n",
    "# The sum of each individual CPU core's utilization. \n",
    "# The CPU utilization of each core can range between 0 and 100. For example, if there are four CPUs, CPUUtilization can range from 0% to 400%.\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, namespace_name=\"/aws/sagemaker/Endpoints\",\n",
    "    metric_name=\"CPUUtilization\", variant_names=variant_names, start_time=start_time, end_time=end_time)\n",
    "\n",
    "# Invocations\n",
    "# The number of requests sent to a model endpoint.\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, namespace_name=\"AWS/SageMaker\", metric_name=\"Invocations\",\n",
    "    variant_names=variant_names, start_time=start_time, end_time=end_time)\n",
    "\n",
    "# InvocationsPerInstance\n",
    "# The number of invocations sent to a model, normalized by InstanceCount in each production variant.\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, namespace_name=\"AWS/SageMaker\", metric_name=\"InvocationsPerInstance\",\n",
    "    variant_names=variant_names, start_time=start_time, end_time=end_time)\n",
    "\n",
    "# ModelLatency\n",
    "# The interval of time taken by a model to respond as viewed from SageMaker (in microseconds).\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, namespace_name=\"AWS/SageMaker\", metric_name=\"ModelLatency\",\n",
    "    variant_names=variant_names, start_time=start_time, end_time=end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82a81b6-14a3-46d8-b343-16fa01142690",
   "metadata": {},
   "source": [
    "<a name='c3w2-4.'></a>\n",
    "# 4. Configure one variant to autoscale\n",
    "\n",
    "Let's configure Variant B to autoscale. You would not autoscale Variant A since no traffic is being passed to it at this time.\n",
    "First, you need to define a scalable target. It is an AWS resource and in this case you want to scale a `sagemaker` resource as indicated in the `ServiceNameSpace` parameter. Then the `ResourceId` is a SageMaker Endpoint. Because autoscaling is used by other AWS resources, you’ll see a few parameters that will remain static for scaling SageMaker Endpoints. Thus the `ScalableDimension` is a set value for SageMaker Endpoint scaling.\n",
    "You also need to specify a few key parameters that control the min and max behavior for your Machine Learning instances. The `MinCapacity` indicates the minimum number of instances you plan to scale in to. The `MaxCapacity` is the maximum number of instances you want to scale out to. So in this case you always want to have at least 1 instance running and a maximum of 2 during peak periods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f48edae-f3ac-4514-bc83-08f2169ecdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoscale.register_scalable_target(\n",
    "    ServiceNamespace=\"sagemaker\", ResourceId=\"endpoint/\" + model_ab_endpoint_name + \"/variant/VariantB\",\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\", MinCapacity=1, MaxCapacity=2, RoleARN=role,\n",
    "    SuspendedState={\"DynamicScalingInSuspended\": False, \"DynamicScalingOutSuspended\": False, \"ScheduledScalingSuspended\": False,},)\n",
    "\n",
    "waiter = sm.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=model_ab_endpoint_name)\n",
    "\n",
    "#Check that the parameters from the function above are in the description of the scalable target:\n",
    "autoscale.describe_scalable_targets(ServiceNamespace=\"sagemaker\", MaxResults=100,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d475d90c-e6e1-4994-9583-70e6d5288034",
   "metadata": {},
   "source": [
    "Define and apply scaling policy using the `put_scaling_policy` function. The scaling policy provides additional information about the scaling behavior for your instance. `TargetTrackingScaling` refers to a specific autoscaling type supported by SageMaker, that uses a scaling metric and a target value as the indicator to scale.\n",
    "In the scaling policy configuration, you have the predefined metric `PredefinedMetricSpecification` which is the number of invocations on your instance and the `TargetValue` which indicates the number of invocations per ML instance you want to allow before triggering your scaling policy. A scale out cooldown of 60 seconds means that after autoscaling successfully scales out it starts to calculate the cooldown time. The scaling policy won’t increase the desired capacity again until the cooldown period ends.\n",
    "The scale in cooldown setting of 300 seconds means that SageMaker will not attempt to start another cooldown policy within 300 seconds of when the last one completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d93f1-f08e-4b43-b2e9-afbf1e66b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoscale.put_scaling_policy(\n",
    "    PolicyName=\"bert-reviews-autoscale-policy\", ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=\"endpoint/\" + model_ab_endpoint_name + \"/variant/VariantB\",\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    PolicyType=\"TargetTrackingScaling\",\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        \"TargetValue\": 2.0, # the number of invocations per ML instance you want to allow before triggering your scaling policy\n",
    "        \"PredefinedMetricSpecification\": {\n",
    "            \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\", # scaling metric\n",
    "        },\n",
    "        \"ScaleOutCooldown\": 60, # wait time, in seconds, before beginning another scale out activity after last one completes\n",
    "        \"ScaleInCooldown\": 300,},) # wait time, in seconds, before beginning another scale in activity after last one completes\n",
    "\n",
    "waiter = sm.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=model_ab_endpoint_name)\n",
    "\n",
    "#Generate traffic again and review the endpoint in the AWS console.\n",
    "#%%time\n",
    "for i in range(0, 100):\n",
    "    predicted_classes = predictor.predict(inputs)\n",
    "    \n",
    "#Review the autoscaling:\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST endpoint</a></b>'.format(region, model_ab_endpoint_name)))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
